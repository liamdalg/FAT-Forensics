# Overview
The core FAT package was developed by researchers at the University of Bristol, with sponsorship from Thales UK. 

Our client would like to work with us to investigates the Fairness, Accountability, and Transparency (FAT) of predictive algorithms. This is the front and back end for a web application which will connect to FAT. It can load datasets into a database, retrieve existing datasets, display and compare data points, generate metrics which evaluate ML fairness, accountability, and transparency metrics, provide interactive plots, and export these reports into PDFs.

Our goal is to democratise assessing social aspects and potentially detrimental effects of predictive models by providing an open source Python package licensed under BSD3 with easy to use Application Programming Interface (API) and minimal dependencies (SciPy and Numpy). The package is intended to be easily integrable with scikit-learn: the most popular and leading open source Python package for doing ML. With the abundance of novel FAT methods, a common open source framework could lower the entry barrier to this research field. Just like scikit-learn allows non-experts to fiddle around with state-of-the-art ML algorithms, we hope that the software framework that is the outcome of our research could allow a broader AI community and lay ML users to test and evaluate their algorithms for security issues, biases, discriminations and unexpected behaviour.

Our key problem is that poorly informed AI system through lack of data can negatively impact the reliability of AI functions. Our tool should be used to represent and analyse these impacts and apply functions on given datasets to try and create more reliable results.

Users will be able to create their own dataset or open an exist dataset in our webpage. They can add or delate any nodes and perform function on dataset. Names and descriptions can also be added to each data. There will be an workflow view and inspector view available which user can modify dataset in workflow view and compare models, read perdictions in inspector view. Lastly, users can choose to generate a PDF report about the fairness, accountability, and transparency of the dateset.